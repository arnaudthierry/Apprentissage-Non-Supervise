# Objectif : Optimisation de l'objectif dans l'algorithme K-means

# 1 - Objectif d'optimisation

Dans les cours précédents, les cours 1 et 2 de la spécialisation, vous avez vu de nombreux algorithmes d'apprentissage supervisé comme un ensemble de formation posant une fonction de coût. Ensuite, utilisez la descente de gradient ou d'autres algorithmes pour optimiser cette fonction de coût. Il s'avère que l'algorithme K-means que vous avez vu optimise également une fonction de coût spécifique. Bien que l'algorithme d'optimisation qu'il utilise soit différent, le processus vise à minimiser une fonction de coût définie.

# 2 -  Fonction de coût de K-means

Voyons ce qu'est la fonction de coût pour K-means. Pour commencer, rappelons que $$c^{(i)}$$ est l'indice du cluster auquel l'exemple d'entraînement $$x^{(i)}$$ est actuellement affecté, et $$\mu_k$$ est l'emplacement du centroïde du cluster $$k$$.

La fonction de coût $$J$$, que K-means essaie de minimiser, est définie comme suit :

$$
J = \frac{1}{m} \sum_{i=1}^{m} \| x^{(i)} - \mu_{c^{(i)}} \|^2 
$$

où 
$$m$$
est le nombre de points de données, 
$$x^{(i)}$$
est un point de données, 
$$\mu_{c^{(i)}}$$
est le centroïde du cluster assigné, et 
$$\| \cdot \|$$
représente la distance euclidienne.

En d'autres termes, la fonction de coût pour K-means est la distance au carré moyenne entre chaque exemple d'entraînement $$x^{(i)}$$ et l'emplacement du centroïde du cluster auquel l'exemple a été attribué.

# 3 - Minimisation de la fonction de coût

L'objectif de K-means est de trouver l'attribution des points aux clusters ainsi que l'emplacement des centroïdes des clusters qui minimisent cette fonction de coût.

# 4 - Illustration visuelle

Voici ce que vous avez vu précédemment avec K-means :
- À chaque étape, K-means met à jour les attributions des clusters $$c^{(i)}$$ et les positions des centroïdes des clusters $$\mu_k$$ afin de continuer à réduire cette fonction de coût $$J$$.
- Cette fonction de coût $$J$$ est également appelée fonction de distorsion dans la littérature.

# 5 - Pourquoi K-means minimise la fonction de coût

## 5.1 - Première étape : Affectation des points aux clusters

Lors de la première étape de K-means, où les points sont attribués aux centroïdes des clusters, l'objectif est de mettre à jour les $$c^{(i)}$$ pour minimiser autant que possible la fonction de coût $$J$$ tout en gardant les $$\mu_k$$ fixes.

Pour minimiser 

$$
\| x^{(i)} - \mu_{c^{(i)}} \|^2
$$

vous devez attribuer $$x^{(i)}$$ au centroïde le plus proche, ce qui est exactement ce que fait l'algorithme K-means.

## 5.2 - Deuxième étape : Mise à jour des centroïdes

Lors de la deuxième étape de K-means, où les centroïdes des clusters sont déplacés, l'objectif est de mettre à jour les $$\mu_k$$ pour minimiser la fonction de coût ou la distorsion tout en gardant les 

$$c^{(i)}$$ 

fixes.

Choisir $$\mu_k$$ comme étant la moyenne des points attribués minimise cette expression. Par exemple, si vous avez un cluster avec seulement deux points, déplacer le centroïde vers la moyenne des deux points réduit la distance carrée moyenne.

## 5.3 - Convergence de K-means

Le fait que l'algorithme K-means optimise une fonction de coût $$J$$ signifie que sa convergence est garantie. À chaque itération, la fonction de coût de distorsion doit diminuer ou rester la même. Si elle augmente, cela signifie qu'il y a une erreur dans le code.

Une fois que la fonction de coût cesse de baisser, cela indique que K-means a convergé. Vous pouvez alors arrêter l'algorithme. Si la diminution de la fonction de coût devient très lente, il peut être raisonnable de considérer que l'algorithme a suffisamment convergé.

## 5.4 -Utilisation des initialisations multiples

Il existe une méthode utile pour améliorer les résultats de K-means : utiliser plusieurs initialisations aléatoires différentes des centroïdes des clusters. Cela permet souvent de trouver de meilleurs clusters.

En suivant ces étapes, l'algorithme K-means parvient à organiser les données en clusters, révélant ainsi la structure sous-jacente des données.

# 6 - Exemple de mise à jour des centroïdes

Pour une assignation fixée des points aux clusters, nous devons mettre à jour la position de chaque centroïde. Cette mise à jour se fait en calculant la moyenne des positions des points assignés à chaque cluster. Mathématiquement, cela signifie que le nouveau centroïde 

$$
\boldsymbol{\mu}_k
$$ 

pour le cluster 

$$
C_k
$$ 

est donné par :

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/038b4417-66b7-4e4d-bbee-32223c6b34dd)



où :
- $$\boldsymbol{\mu}_k$$ est le centroïde du cluster $$C_k$$.
- $$|C_k|$$ est le nombre de points dans le cluster $$C_k$$.
- $$\mathbf{x}$$ représente les points assignés au cluster $$C_k$$.

Cette formule signifie que nous calculons la moyenne des coordonnées de tous les points dans le cluster $$C_k$$ pour obtenir la nouvelle position du centroïde.



## 6.1. Code Python pour la mise à jour des centroïdes

Voici comment cette étape est implémentée dans le code Python :

```python
def calculate_new_centres(clusters: List[PointList]):
    """ Calcule les nouveaux centres des clusters """
    new_centres = PointList(marker="o")
    for cluster in clusters:
        new_centres.append(
            Point(
                x=cluster.x_avg,  # Nouvelle coordonnée x égale à la moyenne des valeurs x de tous les points du cluster
                y=cluster.y_avg,  # Nouvelle coordonnée y égale à la moyenne des valeurs y de tous les points du cluster
                color=cluster.colors[0],  # La couleur du premier point (pour la visualisation)
                magnitude=150  # Les centres sont affichés un peu plus grands pour les identifier visuellement
            )
        )
    return new_centres
```

Cette fonction parcourt chaque cluster, calcule la moyenne des coordonnées des points dans le cluster, et crée un nouveau centroïde à cette position moyenne.

En résumé, l'étape de mise à jour des centroïdes consiste à recalculer la position de chaque centroïde comme la moyenne des positions des points assignés à ce cluster. Cette étape est cruciale pour garantir que les centroïdes se déplacent vers les positions optimales, minimisant ainsi la fonction de coût de l'algorithme K-means.


![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/df43b754-8ad1-4265-9772-b8d3485dd5da)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/3c9f6e6a-bd32-4c55-b9b0-65043b66fb25)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/a5eb0ffd-52e9-4e44-b11e-957b96e4287b)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/039fa7bf-f992-411b-82a8-b0550079ad8c)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/3dbcc9c9-0900-4656-a53d-f95d8c7b0074)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/e227c54f-3779-4b40-817b-8101bb0400fd)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/787114e7-c9a5-4a64-aff7-5f21056a5c73)

# Citations:
- [1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/19265956/6edd8479-6ac0-4ada-b7c1-7236f14d28d8/paste.txt
- [2] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/19265956/1016b69d-043a-42dd-b4bf-b16711be24fa/paste-2.txt
- [3] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/19265956/915a5827-da73-41f0-99bd-7505326d3a65/paste.txt
- [4] https://proceedings.neurips.cc/paper/1994/file/a1140a3d0df1c81e24ae954d935e8926-Paper.pdf
- [5] https://cseweb.ucsd.edu/~dasgupta/291-unsup/lec2.pdf
- [6] https://www.khoury.northeastern.edu/home/hand/teaching/cs6140-fall-2021/Day-18-K-Means-Clustering.pdf
- [7] https://en.wikipedia.org/wiki/K-means_clustering
- [8] https://perso.telecom-paristech.fr/bonald/documents/kmeans.pdf
- [9] https://www.kdnuggets.com/2020/06/centroid-initialization-k-means-clustering.html
- [10] http://www.cs.yale.edu/homes/el327/datamining2013aFiles/10_k_means_clustering.pdf
- [11] https://en.wikipedia.org/wiki/K-means%2B%2B
- [12] https://pubs.aip.org/aip/jcp/article/156/5/054109/2840662/Elucidating-the-solution-structure-of-the-K-means
- [13] https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a
- [14] https://stats.stackexchange.com/questions/188087/proof-of-convergence-of-k-means
- [15] https://stats.stackexchange.com/questions/234758/how-does-initialization-in-k-means-take-place
- [16] https://real-statistics.com/multivariate-statistics/cluster-analysis/initializing-clusters-k-means/
- [17] https://stackoverflow.com/questions/24463964/what-is-convergence-in-k-means
- [18] https://wei2624.github.io/MachineLearning/usv_kmeans/
- [19] https://stackoverflow.com/questions/21259710/k-means-clustering-uniqueness-of-solution
- [20] https://www.machinelearningplus.com/predictive-modeling/k-means-clustering/
