# Comment choisir le nombre optimal de clusters (k) dans l'algorithme k-means ?

- L'algorithme k-means est une technique de clustering non supervisée populaire qui partitionne les données en k clusters. Cependant, une des principales limitations de cet algorithme est qu'il nécessite de spécifier à l'avance le nombre de clusters k à former.
- Choisir une valeur appropriée de k est crucial pour obtenir un clustering significatif des données.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/c79da3cc-4b20-4360-81c1-ecf9a9824be5)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0ba4ac64-81e6-4821-8a1e-1fa803914b20)
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/56cdb11c-3edb-45c7-b5ca-9f7428876688)



- Je vous propose quelques méthodes couramment utilisées pour déterminer le nombre optimal de clusters :

# 1. Méthode du coude (Elbow Method)


La méthode du coude est l'une des techniques les plus populaires pour estimer le nombre optimal de clusters. Elle consiste à exécuter l'algorithme k-means pour différentes valeurs de k, en calculant à chaque fois la somme des carrés des distances de chaque point à son centroïde de cluster (inertie intra-cluster). On trace ensuite un graphique de l'inertie intra-cluster en fonction du nombre de clusters k.
![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/0c88e4ee-fe43-416f-9551-0cf3e79f7a76)
La courbe obtenue décroît généralement de manière prononcée au début, puis commence à se stabiliser à un certain point, formant un "coude". Le nombre optimal de clusters k est choisi au niveau de ce coude, où l'ajout de clusters supplémentaires n'apporte qu'une faible amélioration de l'inertie intra-cluster.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/a5ddadc1-800c-446a-a3e5-db8abd3e82ab)
Bien que cette méthode soit simple et intuitive, elle peut être subjective et sensible aux valeurs aberrantes. De plus, le coude n'est pas toujours évident à identifier, en particulier lorsque la courbe est lisse.

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/ede03ba6-eff5-4270-90ae-658c34c28a8d)


![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/72ee23e3-80aa-4bdb-b12f-c5a7cfad1104)

# 2. Coefficient de silhouette

Le coefficient de silhouette est une mesure de la similitude d'un point de données avec son propre cluster par rapport aux autres clusters. Il varie entre -1 et 1, où une valeur proche de 1 indique que le point de données est bien affecté à son cluster.

Pour trouver le nombre optimal de clusters, on calcule le coefficient de silhouette moyen pour différentes valeurs de k. Le nombre de clusters k qui maximise le coefficient de silhouette moyen est considéré comme optimal.

Cette méthode prend en compte à la fois la compacité des clusters (cohésion) et la séparation entre les clusters. Cependant, elle peut être coûteuse en calcul pour de grands ensembles de données.

#  3. Statistique d'écart (Gap Statistic)

La statistique d'écart compare la somme des carrés intra-cluster pour différentes valeurs de k avec leur distribution attendue sous une hypothèse nulle de référence (généralement des données uniformément réparties). Le nombre optimal de clusters est celui qui maximise l'écart entre le log(Wk) observé et son espérance sous l'hypothèse nulle.

Cette méthode est plus robuste que la méthode du coude, mais elle nécessite de simuler des données de référence, ce qui peut être coûteux en temps de calcul.

#  4. Connaissances du domaine

Dans certains cas, le nombre de clusters peut être déterminé par des connaissances préalables sur le domaine d'application ou par des contraintes métier. Par exemple, dans la segmentation de la clientèle, le nombre de clusters peut être choisi en fonction de critères marketing ou de stratégies de vente.

En pratique, il est souvent recommandé d'utiliser plusieurs de ces méthodes en parallèle et de combiner les résultats avec une expertise du domaine pour choisir le nombre optimal de clusters. De plus, il est important de garder à l'esprit que le clustering est un processus exploratoire et que le nombre de clusters peut être ajusté en fonction des besoins et des interprétations.

Citations:
- [1] https://openclassrooms.com/fr/courses/4525281-realisez-une-analyse-exploratoire-de-donnees/5177935-decouvrez-l-algorithme-k-means
- [2] https://datascientest.com/algorithme-des-k-means
- [3] https://fastercapital.com/fr/contenu/Analyse-de-cluster---techniques-d-analyse-de-cluster---des-K-moyennes-au-clustering-hierarchique.html
- [4] https://blent.ai/blog/a/k-means-comment-ca-marche
- [5] https://www.youtube.com/watch?v=0NqAmRzqeoE
- [6] https://stacklima.com/methode-du-coude-pour-une-valeur-optimale-de-k-en-kmeans/
- [7] https://fastercapital.com/fr/sujet/choisir-le-bon-nombre-de-clusters-%28k%29.html
- [8] https://fr.linkedin.com/advice/0/how-do-you-choose-best-k-elbow-method-cluster?lang=fr
- [9] https://ichi.pro/fr/methode-du-coude-vs-coefficient-de-silhouette-pour-determiner-le-nombre-de-clusters-56878238252782


# Annexe résumé pour déterminer le Nombre de Clusters \( K \) en K-means

L'algorithme K-means nécessite que vous choisissiez le nombre de clusters \( K \) que vous souhaitez trouver dans votre ensemble de données. Mais comment décidez-vous du nombre de clusters à utiliser ? Voulez-vous deux clusters, trois clusters, cinq clusters ou même dix clusters ? Examinons ce problème plus en détail.

# 1 - Ambiguïté du Nombre de Clusters

Pour de nombreux problèmes de clustering, la bonne valeur de \( K \) est souvent ambiguë. Si vous montrez le même ensemble de données à différentes personnes et que vous leur demandez combien de clusters elles voient, certaines personnes diront qu'il semble y avoir deux groupes distincts et elles auront raison. D'autres diront qu'il y a quatre groupes distincts et elles auront également raison. Le clustering étant un algorithme d'apprentissage non supervisé, il n'y a pas de réponse "correcte" unique en termes de nombre de clusters.

# 2 - Méthode du Coude

Une des méthodes couramment mentionnées pour choisir le nombre de clusters est la méthode du coude. Pour appliquer cette méthode, vous pouvez exécuter K-means avec diverses valeurs de \( K \) et tracer la fonction de coût (ou fonction de distorsion) \( J \) en fonction du nombre de clusters. Ce que vous observez souvent est que lorsque vous avez très peu de clusters, la fonction de coût \( J \) est élevée et, à mesure que vous augmentez le nombre de clusters, elle diminue rapidement puis plus lentement.

Par exemple, si la courbe de la fonction de coût ressemble à ceci :
```
J
|
|         _______
|       /
|     /
|___/
|__________ K
```
Le point où la diminution devient plus lente est appelé le "coude" de la courbe. Dans cet exemple, le coude se situe autour de trois clusters, donc vous pourriez choisir \( K = 3 \).

# 3 - Limites de la Méthode du Coude

Cependant, cette méthode n'est pas toujours fiable. Pour de nombreuses applications, le bon nombre de clusters est vraiment ambigu et la courbe de la fonction de coût ne présente pas toujours un coude clair. De plus, choisir \( K \) pour minimiser la fonction de coût \( J \) n'est pas une bonne technique, car cela vous inciterait presque toujours à choisir la plus grande valeur possible de \( K \). En effet, avoir plus de clusters réduit presque toujours la fonction de coût \( J \).

# 4 -  Évaluation Basée sur l'Utilisation Ultérieure

Une approche plus pratique consiste à évaluer K-means en fonction de ses performances pour une utilisation ultérieure ou en aval. Par exemple, si vous utilisez K-means pour déterminer les tailles de t-shirts, vous pouvez comparer les résultats pour \( K = 3 \) (petit, moyen, grand) et \( K = 5 \) (très petit, petit, moyen, grand, très grand). La décision entre trois ou cinq tailles de t-shirts peut être prise en fonction de ce qui convient le mieux à votre entreprise, en tenant compte des coûts supplémentaires de fabrication et d'expédition de cinq tailles au lieu de trois.

# 5 - Exercice Pratique : Compression d'Images

Un exemple visuel amusant de K-means est l'application à la compression d'images. Vous pouvez exécuter K-means avec différentes valeurs de \( K \) et observer le compromis entre la qualité de l'image compressée et la quantité de compression. Cela vous permet de choisir manuellement la meilleure valeur de \( K \) en fonction de la qualité d'image souhaitée et de la taille de fichier acceptable.

# 6 - Conclusion

Choisir le bon nombre de clusters \( K \) est souvent un processus ambigu et subjectif. En fin de compte, l'évaluation basée sur l'utilisation pratique et les exigences spécifiques de votre application est la meilleure approche. En utilisant K-means avec plusieurs valeurs de \( K \) et en comparant les résultats, vous pouvez prendre une décision éclairée qui répond le mieux à vos besoins.

---

# Annexe 2 -  Exécution de K-means avec Initialisations Multiples

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/da74f81c-138d-46ac-a114-d8901b8b8e25)

---

![image](https://github.com/hrhouma/Apprentissage-Non-Supervise-1/assets/10111526/b7e35a1d-2418-45fc-a874-13ee0b77868d)
